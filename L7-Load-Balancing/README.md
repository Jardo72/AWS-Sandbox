# L7 Load-Balancing Demo

## Introduction
L7 Load-Balancing Demo is an experimantal/educational application meant as illustration of L7 (aka application) load balancing in combination with AWS, Docker, Kubernetes etc. It is a Java application based on the SpringBoot framework which exposes 3 groups of REST API endpoints:
- Load-Balancing Demonstration API
- Health Check API
- CPU Load API

Details for each of the three API endpoint groups are described below. In order to submit REST requests to the application, use a tool like [Postman](https://www.postman.com) or [curl](https://curl.se). Unless you override the default configuration, the application is listening on port 80, so you do not need to specify the port in the URLs. As the application does not deal with any sensitive data, there is no need for security. In addition, I wanted to make the application as simple and cheap as possible. Therefore, the REST API exposed by the application is accessible via plain HTTP (i.e. not via HTTPS).


#### Load-Balancing Demonstration API
Load-balancing demonstration API involves single API endpoint (`GET /api/system-info`) that can be used to illustrate various aspects of load balancing. The response returned by this API endpoint involves the following information:
- The number of REST requests handled so far by the application. There is a counter which is incremented whenever this API endpoint is involved, and there are similar counters for the health check API endpoint and the CPU load API endpoint.
- Information about the server process and the host where it is running (hostname, username, number of processors available).
- Information about the connection used to deliver the current request (e.g. IP address/TCP port for both client and server). In case of L7 load balancing, the client IP address is in fact the IP address of the load balancer (not the client the request originates from).
- All HTTP headers present in the request. The purpose is to illustrate the `X-Forwarded-*` headers which are added by some load balancers like AWS ALB.

The following JSON snippet illustrates the response generated by this endpoint. In this particular case, the application was running on a single AWS EC2 instance without any load balancer, so there are no `X-Forwarded-*` headers.

```json
{
    "serverInformation": {
        "username": "root",
        "hostname": "ip-172-31-37-195.eu-central-1.compute.internal",
        "availableProcessors": 1
    },
    "requestInformation": {
        "scheme": "http",
        "clientEndpoint": {
            "address": "178.143.40.137",
            "port": 50074
        },
        "serverEndpoint": {
            "address": "172.31.37.195",
            "port": 80
        },
        "httpHeaders": [
            {
                "name": "user-agent",
                "values": [
                    "PostmanRuntime/7.26.8"
                ]
            },
            {
                "name": "accept",
                "values": [
                    "*/*"
                ]
            },
            {
                "name": "cache-control",
                "values": [
                    "no-cache"
                ]
            },
            {
                "name": "postman-token",
                "values": [
                    "f7bde5e7-299a-45fe-8a69-dc338fb06f77"
                ]
            },
            {
                "name": "host",
                "values": [
                    "54.93.110.239"
                ]
            },
            {
                "name": "accept-encoding",
                "values": [
                    "gzip, deflate, br"
                ]
            },
            {
                "name": "connection",
                "values": [
                    "keep-alive"
                ]
            }
        ],
        "secure": false
    },
    "statisticInformation": {
        "systemInfoRequestCount": 1,
        "healthCheckCount": 0,
        "primeNumbersCalculationCount": 0
    }
}
```

The project also involves a simple client application written in Python that can be used to generate many `GET /api/system-info` requests. The client application consists of a single Python file ([system-info-client.py](./system-info-client.py)), and it expects 3 command line arguments:
- The hostname or IP address of the backend. If a load balancer is in front of the backend, the hostname or the IP address of the load balancer is to be used.
- The TCP port of the backend. If load balancer is used, the TCP port of the load balancer is to be used.
- The number of requests to be sent.

The application is single-threaded, so it sends the requests sequentially. After sending the specified number of requests, the client application prints the number of requests handled by particular backend instances. The following snippet illustrates the output generated by the client application.

```
--------------------------------------------------------------------------------
- Test Parameters
--------------------------------------------------------------------------------
Host:          L7-Load-Balancing-Demo-ALB-1572882261.eu-central-1.elb.amazonaws.com
Port:          80
Request count: 1000


--------------------------------------------------------------------------------
- Requests
--------------------------------------------------------------------------------
250 of 1000 requests completed...
500 of 1000 requests completed...
750 of 1000 requests completed...
1000 of 1000 requests completed...


--------------------------------------------------------------------------------
- Summary (statistics)
--------------------------------------------------------------------------------

Requests per server:
   172.31.17.149:     334
   172.31.35.165:     333
     172.31.9.20:     333

Requests per HTTP status code:
200:    1000
```

#### Health Check API
Health check API involves an API endpoint (`GET /api/health-check`) that is supposed to be used as load balancer health check. In addition, there are two additional endpoints that can be used to control the behavior of the above mentioned health check endpoint:
- `PUT /api/health-status?status=<STATUS>` allows to specify the outcome of subsequent invocations of the health check endpoint. The query string parameter `status` can have one of the following three values: the value `OK` (default) specifies that subsequent health checks will succeed with HTTP status 200; the value `ERROR` means that health checks will fail with HTTP status 500; and the value `HANG` will cause that subsequent health checks will block the thread handling the health check request forever (i.e. the load balancer health check will most likely fail with timeout).
- `GET /api/health-status` returns the current status (i.e. the value specified by the last PUT request).

#### CPU Load API
CPU load API involves just a single endpoint (`POST /api/calculate-prime-numbers`) that can be used to trigger calculation of prime numbers and thus high CPU load. If this application is deployed to an AWS auto scaling group, this API endpoint can be used to demonstrate the auto scaling. The POST request is supposed to carry the following JSON body specifying the desired range for the calculation:

```json
{
    "start": 1,
    "end":   900000000
}
```

Besides auto scaling, this API endpoint can also be used to demonstrate AWS CloudWatch metrics and alarms.

## Source Code Organization and Building
The application is organized as a simple Maven project. In order to build the applications, just navigate to the root directory of the project and execute the following command (assumed Maven is installed and properly configured):

```
mvn clean package
```

The command above builds a fat runnable JAR file with all dependencies (including Spring and embedded HTTP server) which can be immediately used to start the application. The name of the JAR file is `aws-sandbox-application-load-balancing-server-1.0.jar`, and it resides in the `target` directory.

## How to Start the Service
The fat runnable JAR file mentioned in the previous section also involves `application.properties` file allowing to configure the application. The default configuration binds the embedded HTTP server to all available network interfaces (i.e. 0.0.0.0), so in the vast majority of cases, there is no need to change this. The default configuration binds the embedded HTTP server to the TCP port 80, which should also be OK for most use cases. The following command illustrates how to start the application with the default settings.

```
java -jar ./target/aws-sandbox-application-load-balancing-server-1.0.jar
```

The above mentioned default settings can be overwritten by Java system properties when starting the application. The following command illustrates how to bind the HTTP server to the network interface with the IP address 192.168.0.10 and to the TCP port 8080.

```
java -Dserver.address=192.168.0.10 -Dserver.port=8080 -jar ./target/aws-sandbox-application-load-balancing-server-1.0.jar
```

## How to Deploy the Application to AWS

### Application Load Balancer + EC2 Auto Scaling Group
The project involves parametrized CloudFormation template that will automatically create a setup with an application load balancer and an EC2 auto scaling group running several instances of the application. The CloudFormation template creates a complete stack with the following resources:
* custom VPC with three public subnets (each in separate AZ), Internet Gateway and custom route table with a route to the Internet Gateway
* Internet-facing application load balancer
* two security groups - one protecting the load balancer, the other proptecting the EC2 instances
* launch template for the EC2 instances, with user data involving download of the application JAR from an S3 bucket
* EC2 auto scaling group with ELB health checks and target tracking scaling policy that dynamically adjusts the number of the EC2 instances based on the CPU utilization

The following AWS CLI command illustrates how to use the CloudFormation template.
```
aws cloudformation create-stack --stack-name L7-LB-Demo --template-body file://cloud-formation-template.yml --parameters file://stack-params.json --capabilities CAPABILITY_NAMED_IAM --on-failure ROLLBACK
```

### ECS
TODO
