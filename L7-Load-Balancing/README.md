# L7 Load-Balancing Demo

## Introduction
L7 Load-Balancing Demo is an experimantal/educational application meant as illustration of L7 (aka application) load balancing in combination with AWS, Docker, Kubernetes etc. It is a Java application based on the SpringBoot framework which exposes 3 groups of REST API endpoints:
- Load-Balancing Demonstration API
- Health Check API
- CPU Load API

Details for each of the three API endpoint groups are described below. In order to submit REST requests to the application, use a tool like Postman or curl. Unless you override the default configuration, the application is listening on port 80, so you do not need to specify the port in the URLs. As the application does not deal with any sensitive data, there is no need for security. In addition, I wanted to make the application as simple and cheap as possible. Therefore, the REST API exposed by the application is accessible via plain HTTP (i.e. not via HTTPS).


#### Load-Balancing Demonstration API
Load-balancing demonstration API involves single API endpoint (`GET /api/system-info`) that can be used to illustrate various aspects of load balancing. The response returned by this API endpoint involves the following information:
- The number of REST requests handled so far by the application. There is a counter which is incremented whenever this API endpoint is involved, and there are similar counters for the health check API endpoint and the CPU load API endpoint.
- Information about the server process and the host where it is running (hostname, username, number of processors available).
- Information about the connection used to deliver the current request (e.g. IP address/TCP port for both client and server). In case of L7 load balancing, the client IP address is in fact the IP address of the load balancer (not the client the request originates from).
- All HTTP headers present in the request. The purpose is to illustrate the `X-Forwarded-*` headers which are added by some load balancers like AWS ALB.

The following JSON snippet illustrates the response generated by this endpoint. In this particular case, the application was running on a single AWS EC2 instance without any load balancer, so there are no `X-Forwarded-*` headers.

```json
{
    "serverInformation": {
        "username": "root",
        "hostname": "ip-172-31-37-195.eu-central-1.compute.internal",
        "availableProcessors": 1
    },
    "requestInformation": {
        "scheme": "http",
        "clientEndpoint": {
            "address": "178.143.40.137",
            "port": 50074
        },
        "serverEndpoint": {
            "address": "172.31.37.195",
            "port": 80
        },
        "httpHeaders": [
            {
                "name": "user-agent",
                "values": [
                    "PostmanRuntime/7.26.8"
                ]
            },
            {
                "name": "accept",
                "values": [
                    "*/*"
                ]
            },
            {
                "name": "cache-control",
                "values": [
                    "no-cache"
                ]
            },
            {
                "name": "postman-token",
                "values": [
                    "f7bde5e7-299a-45fe-8a69-dc338fb06f77"
                ]
            },
            {
                "name": "host",
                "values": [
                    "54.93.110.239"
                ]
            },
            {
                "name": "accept-encoding",
                "values": [
                    "gzip, deflate, br"
                ]
            },
            {
                "name": "connection",
                "values": [
                    "keep-alive"
                ]
            }
        ],
        "secure": false
    },
    "statisticInformation": {
        "systemInfoRequestCount": 1,
        "healthCheckCount": 0,
        "primeNumbersCalculationCount": 0
    }
}
```

#### Health Check API
Health check API involves an API endpoint (`GET /api/health-check`) that is supposed to be used as load balancer health check. In addition, there are two additional endpoints that can be used to control the behavior of the above mentioned health check endpoint:
- `PUT /api/health-status?status=<STATUS>` allows to specify the outcome of subsequent invocations of the health check endpoint. The query string parameter `status` can have one of the following three values: the value `OK` (default) specifies that subsequent health checks will succeed with HTTP status 200; the value `ERROR` means that health checks will fail with HTTP status 500; and the value `HANG` will cause that subsequent health checks will block the thread handling the health check request forever (i.e. the load balancer health check will most likely fail with timeout).
- `GET /api/health-status` returns the current status (i.e. the value specified by the last PUT request).

#### CPU Load API
CPU load API involves just a single endpoint (`POST /api/calculate-prime-numbers`) that can be used to trigger calculation of prime numbers and thus high CPU load. If this application is deployed to an AWS auto scaling group, this API endpoint can be used to demonstrate the auto scaling. The POST request is supposed to carry the following JSON body specifying the desired range for the calculation:

```json
{
    "start": 1,
    "end":   900000000
}
```

Besides auto scaling, this API endpoint can also be used to demonstrate AWS CloudWatch metrics and alarms.

## Source Code Organization and Building
The application is organized as a simple Maven project. In order to build the applications, just navigate to the root directory of the project and execute the following command (assumed Maven is installed and properly configured):

```
mvn clean package
```

The command above builds a fat runnable JAR file with all dependencies (including Spring and embedded HTTP server) which can be immediately used to start the application. The name of the JAR file is `aws-sandbox-application-load-balancing-server-1.0.jar`, and it resides in the `target` directory.

## How to Start the Service
The fat runnable JAR file mentioned in the previous section also involves `application.properties` file allowing to configure the application. The default configuration binds the embedded HTTP server to all available network interfaces (i.e. 0.0.0.0), so in the vast majority of cases, there is no need to change this. The default configuration binds the embedded HTTP server to the TCP port 80, which should also be OK for most use cases. The following command illustrates how to start the application with the default settings.

```
java -jar ./target/aws-sandbox-application-load-balancing-server-1.0.jar
```

The above mentioned default settings can be overwritten by Java system properties when starting the application. The following command illustrates how to bind the HTTP server to the network interface with the IP address 192.168.0.10 and to the TCP port 8080.

```
java -Dserver.address=192.168.0.10 -Dserver.port=8080 -jar ./target/aws-sandbox-application-load-balancing-server-1.0.jar
```

## How to Deploy the Application to AWS

### EC2
TODO: parametrized CloudFormation template(s) that will create everything from VPC up to ASG + ELB


### ECS
TODO
